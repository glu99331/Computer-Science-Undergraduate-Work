{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e971a8dcd8e4a9c9e3e73c15499d66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_873d342119bf4da4b0aab36ef7bc5a34",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37d2b21a7e994724a36bc0d86769660c",
              "IPY_MODEL_fb350ed424014bc88212d697a86490e5"
            ]
          }
        },
        "873d342119bf4da4b0aab36ef7bc5a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37d2b21a7e994724a36bc0d86769660c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fc01f8479f54945a673ef7430b38392",
            "_dom_classes": [],
            "description": "Epoch [5/5], Step [500/500], Loss: 1.9807: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eb126fa03244d83a1a25a46d57b9008"
          }
        },
        "fb350ed424014bc88212d697a86490e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fce349818974de9b9570b9699f20964",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:44&lt;00:00,  8.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da9754460c864fef87d8935a2eb82292"
          }
        },
        "4fc01f8479f54945a673ef7430b38392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eb126fa03244d83a1a25a46d57b9008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fce349818974de9b9570b9699f20964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da9754460c864fef87d8935a2eb82292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79b4e09591a24fb6a7c907741ec8699d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0841ba25cb0747ff97f7456289ac533b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65a0fc0e92184767acece137d6a9e4dc",
              "IPY_MODEL_cc030f92322a415f80a93647cdb987c3"
            ]
          }
        },
        "0841ba25cb0747ff97f7456289ac533b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65a0fc0e92184767acece137d6a9e4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_395b25ffc75f44a6928324211f47104f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ca567890f85472990e403f7ed2914c1"
          }
        },
        "cc030f92322a415f80a93647cdb987c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a590cb755934bcb97a1c179522c1d03",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:00&lt;00:00, 148.26it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5610838d739d4d49be66803fdbd118b2"
          }
        },
        "395b25ffc75f44a6928324211f47104f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ca567890f85472990e403f7ed2914c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a590cb755934bcb97a1c179522c1d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5610838d739d4d49be66803fdbd118b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5419ad619c44331aebddfa336247e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_443a3461fe1643eaaf08bf748efb6a06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cebad6ff753429da0f437696aea8b5a",
              "IPY_MODEL_fbe8d7e0d29844e2a905b7b9387a5d7b"
            ]
          }
        },
        "443a3461fe1643eaaf08bf748efb6a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cebad6ff753429da0f437696aea8b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0c17da96008487599adffaf1c72f55c",
            "_dom_classes": [],
            "description": "Epoch [1/5], Step [120/500], Loss: 2.1784:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5acc2f2ea784680a4779e575243817e"
          }
        },
        "fbe8d7e0d29844e2a905b7b9387a5d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33ed35d25953423f82f969395d81ad2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/5 [01:27&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c67c318fbeb049ef9971172a527745be"
          }
        },
        "b0c17da96008487599adffaf1c72f55c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5acc2f2ea784680a4779e575243817e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33ed35d25953423f82f969395d81ad2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c67c318fbeb049ef9971172a527745be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PluHMGh9idCj",
        "outputId": "277c12fc-f7b0-4948-e5c3-f2363347fe00"
      },
      "source": [
        "# from zipfile import ZipFile\n",
        "# filename = \"cifar10.zip\"\n",
        "\n",
        "# with ZipFile(filename, 'r') as zip:\n",
        "#   zip.extractall()\n",
        "#   print('Done')\n",
        "\n",
        "#Packages:\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from os import path as ospath\n",
        "from skimage import io\n",
        "import skimage.transform\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW0NL6X25amB"
      },
      "source": [
        "Part A: Building a Custom Data Loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3JVq7Ailrp"
      },
      "source": [
        "class CifarDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root_dir, mobile_net = False):\n",
        "    \"\"\"Initializes a dataset containing images and labels.\"\"\"\n",
        "    super().__init__()\n",
        "    self.img_list = []\n",
        "    self.label_dict = {\n",
        "        \"airplane\": 0,\n",
        "        \"automobile\": 1,\n",
        "        \"bird\": 2,\n",
        "        \"cat\": 3,\n",
        "        \"deer\": 4,\n",
        "        \"dog\": 5,\n",
        "        \"frog\": 6,\n",
        "        \"horse\": 7,\n",
        "        \"ship\": 8,\n",
        "        \"truck\": 9\n",
        "    }\n",
        "    self.root_dir = root_dir\n",
        "    self.mobile_net = mobile_net\n",
        "    #pre-load images (data)\n",
        "    # for k,v in self.label_dict.items():\n",
        "    #   for file in os.listdir(os.path.join(self.root_dir, k)):\n",
        "    #     self.img_list.append([os.path.join(self.root_dir, k, file), self.label_dict[k]])\n",
        "    # #   file = os.listdir(os.path.join(self.root_dir, k))\n",
        "    # # print(sorted(self.label_dict))\n",
        "    for folder in os.listdir(path=root_dir):\n",
        "      for file in os.listdir(path=root_dir+'/'+folder):\n",
        "        # print(root_dir+'/'+folder+'/'+file)\n",
        "        if file.endswith('.png'):\n",
        "          image = io.imread(root_dir+'/'+folder+'/'+file)\n",
        "          self.img_list.append((image, self.label_dict[folder]))\n",
        "        # image = io.imread(root_dir+'/'+folder+'/'+file)\n",
        "        # self.img_list.append((image, folder)) \n",
        "    #     # raise NotImplementedError\n",
        "    self.img_list = np.array(self.img_list)\n",
        "  def __len__(self):\n",
        "    \"\"\"Returns the size of the dataset.\"\"\"\n",
        "    return len(self.img_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Returns the index-th data item of the dataset.\"\"\"\n",
        "\n",
        "    if self.mobile_net is True:\n",
        "      return (skimage.transform.resize(self.img_list[index][0], (224, 224)),self.img_list[index][1])\n",
        "    else:\n",
        "      return (self.img_list[index][0],self.img_list[index][1])"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMNj2OxQ12wj"
      },
      "source": [
        "Part B: Training a neural network in PyTorch (25 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6AG1DC15Ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "0e971a8dcd8e4a9c9e3e73c15499d66c",
            "873d342119bf4da4b0aab36ef7bc5a34",
            "37d2b21a7e994724a36bc0d86769660c",
            "fb350ed424014bc88212d697a86490e5",
            "4fc01f8479f54945a673ef7430b38392",
            "5eb126fa03244d83a1a25a46d57b9008",
            "4fce349818974de9b9570b9699f20964",
            "da9754460c864fef87d8935a2eb82292",
            "79b4e09591a24fb6a7c907741ec8699d",
            "0841ba25cb0747ff97f7456289ac533b",
            "65a0fc0e92184767acece137d6a9e4dc",
            "cc030f92322a415f80a93647cdb987c3",
            "395b25ffc75f44a6928324211f47104f",
            "3ca567890f85472990e403f7ed2914c1",
            "6a590cb755934bcb97a1c179522c1d03",
            "5610838d739d4d49be66803fdbd118b2"
          ]
        },
        "outputId": "fcce634a-0062-43c0-bf8c-edc2c6dc7b29"
      },
      "source": [
        "#3-layer MLP model\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes, dropout = 0.2):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.dropout = nn.Dropout(p = dropout)\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "    self.input_size = input_size\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x.reshape(-1, self.input_size))\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "  \n",
        "def training(training_path, device, model, criterion, optimizer, num_epochs, BATCH_SIZE, mobile_net = False):\n",
        "  train_dataset = CifarDataset(TRAIN_DIRECTORY_PATH)\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True)\n",
        "  min_loss = 10000000.0\n",
        "  total_epochs = tqdm_notebook(range(num_epochs))\n",
        "\n",
        "  model.train() #set the model into training mode\n",
        "  \n",
        "  for epch in total_epochs:\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "      #Move tensors to the configured device\n",
        "      images = images.to(device)\n",
        "      if mobile_net is True:\n",
        "        images = images.permute(0, 3, 1, 2)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      #forward pass\n",
        "      outputs = model(images.float())\n",
        "      labels = labels.type(torch.LongTensor)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      #backward and optimize\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if loss.item() <= min_loss:\n",
        "        min_loss = loss.item()\n",
        "      if (i+1) % 10 == 0:\n",
        "        total_epochs.set_description(\n",
        "            'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epch + 1, NUM_EPOCHS, i + 1, len(train_dataloader), loss.item())\n",
        "        )\n",
        "  print('Min Loss was: {} % '.format(min_loss))\n",
        "def evaluation(test_path, device, model, criterion, BATCH_SIZE, mobile_net = False):\n",
        "  test_dataset = CifarDataset(TEST_DIRECTORY_PATH)\n",
        "  test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in tqdm_notebook(test_dataloader):\n",
        "      images = images.to(device)\n",
        "      if mobile_net is True:\n",
        "        images = images.permute(0, 3, 1, 2)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images.float())\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the test images: {} %'.format(100 * correct/total))\n",
        "#parameters\n",
        "TRAIN_DIRECTORY_PATH = 'cifar10/cifar10_train'\n",
        "TEST_DIRECTORY_PATH = 'cifar10/cifar10_test'\n",
        "NUM_CLASSES = 10\n",
        "NUM_EPOCHS = 20\n",
        "INPUT_SIZE = 32*32*3\n",
        "device = 'cpu'\n",
        "\n",
        "DROP_OUT = 0.5\n",
        "LEARNING_RATE = 0.00005\n",
        "HIDDEN_SIZE = 500\n",
        "BATCH_SIZE = 100\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "model = MultilayerPerceptron(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adamax(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY) \n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY) \n",
        "\n",
        "########\n",
        "def part2():\n",
        "  training(TRAIN_DIRECTORY_PATH, device, model, criterion, optimizer, NUM_EPOCHS, BATCH_SIZE)\n",
        "  evaluation(TEST_DIRECTORY_PATH, device, model, criterion, BATCH_SIZE)\n",
        "\n",
        "part2()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e971a8dcd8e4a9c9e3e73c15499d66c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Min Loss was: 1.9320440292358398 % \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79b4e09591a24fb6a7c907741ec8699d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy of the network on the test images: 25.68 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nGc82QAIYMw"
      },
      "source": [
        "Results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RssIikaIaEd",
        "outputId": "6b0904be-6373-44e8-a5d3-4ffdcb82cebd"
      },
      "source": [
        "# Here, I tinkered around with 3 different learning rates:\n",
        "n = [10]*3\n",
        "lr = [0.0001, 0.00001, 0.00005]\n",
        "d_out = [0.2]*3\n",
        "h_size = [500]*3\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.5]*3\n",
        "b_size = [100]*3\n",
        "l = [1.8089, 1.6517, 1.6826]\n",
        "a = [32.58, 36.92, 36.38]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           10 |          0.0001 |        0.2 |           500 | Adamax      |            0.5 |          100 | 1.8089 |      32.58 |\n",
            "|  1 |           10 |          1e-05  |        0.2 |           500 | Adamax      |            0.5 |          100 | 1.6517 |      36.92 |\n",
            "|  2 |           10 |          5e-05  |        0.2 |           500 | Adamax      |            0.5 |          100 | 1.6826 |      36.38 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYrJfX8EKZWg",
        "outputId": "8633a6dd-9148-4e83-bf3c-b54e0ad2bc70"
      },
      "source": [
        "# Now I fix the Learning Rate as the ones that yielded the best accuracy and lowest loss, and tinker around with Drop Out\n",
        "n = [10]*3\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5, 0.6, 0.7]\n",
        "h_size = [500]*3\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.5]*3\n",
        "b_size = [100]*3\n",
        "l = [1.6588, 1.6885, 1.6704]\n",
        "a = [36.12, 35.89, 35.12]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           10 |           5e-05 |        0.5 |           500 | Adamax      |            0.5 |          100 | 1.6588 |      36.12 |\n",
            "|  1 |           10 |           5e-05 |        0.6 |           500 | Adamax      |            0.5 |          100 | 1.6885 |      35.89 |\n",
            "|  2 |           10 |           5e-05 |        0.7 |           500 | Adamax      |            0.5 |          100 | 1.6704 |      35.12 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtYnF8VHN5vc",
        "outputId": "992cb046-7a0c-4f71-bf76-a9e8ad44bc82"
      },
      "source": [
        "# Now I fix the Learning Rate and Drop Out as the ones that yielded the best accuracy and lowest loss, and tinker around with Weight Decay\n",
        "n = [10]*3\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5]*3\n",
        "h_size = [500]*3\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.001, 0.0001, 0.00001]\n",
        "b_size = [100]*3\n",
        "l = [1.5759, 1.5669, 1.5727]\n",
        "a = [36.83, 36.87, 36.61]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           10 |           5e-05 |        0.5 |           500 | Adamax      |         0.001  |          100 | 1.5759 |      36.83 |\n",
            "|  1 |           10 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          100 | 1.5669 |      36.87 |\n",
            "|  2 |           10 |           5e-05 |        0.5 |           500 | Adamax      |         1e-05  |          100 | 1.5727 |      36.61 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE127CCbQAay",
        "outputId": "3dd235b7-634f-45b0-ab0e-476e1627f387"
      },
      "source": [
        "# Now I fix the Learning Rate, Drop Out and Weight Decay as the ones that yielded the best accuracy and lowest loss, and tinker around with the Number of Epochs\n",
        "n = [10, 15, 20]\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5]*3\n",
        "h_size = [400, 500, 600]\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.0001]*3\n",
        "b_size = [100]*3\n",
        "l = [1.5364, 1.5097, 1.5279]\n",
        "a = [36.85, 37.5, 37.43]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           10 |           5e-05 |        0.5 |           400 | Adamax      |         0.0001 |          100 | 1.5364 |      36.85 |\n",
            "|  1 |           15 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          100 | 1.5097 |      37.5  |\n",
            "|  2 |           20 |           5e-05 |        0.5 |           600 | Adamax      |         0.0001 |          100 | 1.5279 |      37.43 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ERlILktTEpC",
        "outputId": "a333c59f-e864-40b6-e0a3-8e260e3b571f"
      },
      "source": [
        "# Now I fix the Learning Rate, Drop Out, Weight Decay and Number of Epochs as the one that yielded the best accuracy and lowest loss, and tinker around with the Hidden Size\n",
        "n = [15]*3\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5]*3\n",
        "h_size = [400, 500, 600]\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.0001]*3\n",
        "b_size = [100]*3\n",
        "l = [1.5425, 1.5155, 1.5413]\n",
        "a = [36.13, 37.78, 37.96]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           15 |           5e-05 |        0.5 |           400 | Adamax      |         0.0001 |          100 | 1.5425 |      36.13 |\n",
            "|  1 |           15 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          100 | 1.5155 |      37.78 |\n",
            "|  2 |           15 |           5e-05 |        0.5 |           600 | Adamax      |         0.0001 |          100 | 1.5413 |      37.96 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb58xV4KXaXw",
        "outputId": "9cb4b1de-866d-44e2-85f0-6a1a1ee6f91e"
      },
      "source": [
        "# Now I fix the Learning Rate, Drop Out, Weight Decay, Number of Epochs and Hidden Size as the ones that yielded the best accuracy and lowest loss, and tinker around with the Batch Size\n",
        "n = [15]*3\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5]*3\n",
        "h_size = [500]*3\n",
        "optim = ['Adamax']*3\n",
        "w_decay = [0.0001]*3\n",
        "b_size = [32, 64, 128]\n",
        "l = [1.3237,1.4838, 1.5711]\n",
        "a = [37.35,38.12, 38.01]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 |           15 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |           32 | 1.3237 |      37.35 |\n",
            "|  1 |           15 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |           64 | 1.4838 |      38.12 |\n",
            "|  2 |           15 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          128 | 1.5711 |      38.01 |\n",
            "+----+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpJx49Jboh6"
      },
      "source": [
        "# Now I fix the Learning Rate, Drop Out, Weight Decay, Number of Epochs, Hidden Size and Batch Size as the ones that yielded the best accuracy and lowest loss, and tinker around with the Optimizers\n",
        "n = [15]*3\n",
        "lr = [0.00005]*3\n",
        "d_out = [0.5]*3\n",
        "h_size = [500]*3\n",
        "optim = ['Adamax', 'SGD', 'RMSProp']\n",
        "w_decay = [0.0001]*3\n",
        "b_size = [64]*3\n",
        "l = [1.3833,1.5253,1.6852]\n",
        "a = [36.83,35.79,28.76]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxFkpkCagwfd"
      },
      "source": [
        "Final Remarks: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFB5LZD2g2TH"
      },
      "source": [
        "The method in which I selected the \"optimal\" hyperparameters is in no way a good way. A better way to choose the optimal hyperparameters would be to use cross-validation, perhaps using a 5-fold or 10-fold and determine which combinations of hyperparameters yield the lowest error. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIf9zlogRFxn"
      },
      "source": [
        "Part C: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460,
          "referenced_widgets": [
            "d5419ad619c44331aebddfa336247e98",
            "443a3461fe1643eaaf08bf748efb6a06",
            "3cebad6ff753429da0f437696aea8b5a",
            "fbe8d7e0d29844e2a905b7b9387a5d7b",
            "b0c17da96008487599adffaf1c72f55c",
            "a5acc2f2ea784680a4779e575243817e",
            "33ed35d25953423f82f969395d81ad2f",
            "c67c318fbeb049ef9971172a527745be"
          ]
        },
        "id": "gnupItsn5sv2",
        "outputId": "539c7ca7-1ab1-4f86-d809-205f63e1ab30"
      },
      "source": [
        "EXTRACT_FEATURES = True #true means we fine tune, false means we don't.\n",
        "def part3():\n",
        "  # (1) freezing all the MobileNetV2 layers (feature extraction) and only train the final classification layer; \n",
        "  # (2) finetuning all MobileNetV2 layers together with the final classification layer.\n",
        "  # Simple flag will do the trick!\n",
        "  # Load MobileNetV2 model\n",
        "  mobile_model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\n",
        "\n",
        "  if EXTRACT_FEATURES is True:\n",
        "    for param in mobile_model.parameters():\n",
        "      param.requires_grad = False\n",
        "  numftrs = mobile_model.classifier[1].in_features\n",
        "  mobile_model.classifier[1] = torch.nn.Linear(in_features = numftrs, out_features=NUM_CLASSES)\n",
        "  mobile_model = mobile_model.to(device)\n",
        "  mobile_criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "  params = mobile_model.parameters()\n",
        "  if EXTRACT_FEATURES is True:\n",
        "    params = []\n",
        "    for n,p in mobile_model.named_parameters():\n",
        "      if p.requires_grad:\n",
        "        params.append(p)\n",
        "  optimizer = torch.optim.SGD(params, LEARNING_RATE, momentum = 0.9)\n",
        "  training(TRAIN_DIRECTORY_PATH, device, mobile_model, mobile_criterion, optimizer, NUM_EPOCHS, BATCH_SIZE, True)\n",
        "  evaluation(TEST_DIRECTORY_PATH, device, mobile_model, BATCH_SIZE, True)\n",
        "part3()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5419ad619c44331aebddfa336247e98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-888b68dad3c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIRECTORY_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIRECTORY_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mpart3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-193-888b68dad3c1>\u001b[0m in \u001b[0;36mpart3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIRECTORY_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DIRECTORY_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpart3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-192-e596d14b3855>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(training_path, device, model, criterion, optimizer, num_epochs, BATCH_SIZE, mobile_net)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m#forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/mobilenetv2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/mobilenetv2.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/mobilenetv2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4PgnOZelt3"
      },
      "source": [
        "Results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHpCsL3xenPI",
        "outputId": "1b5f66a1-9637-44b7-8db0-2835daadfeaf"
      },
      "source": [
        "# I now choose the optimal parameters to run for Freezing\n",
        "t = ['Freezing', 'Fine Tuning']\n",
        "n = [20]*2\n",
        "lr = [0.00005]*2\n",
        "d_out = [0.5]*2\n",
        "h_size = [500]*2\n",
        "optim = ['Adamax']*2\n",
        "w_decay = [0.0001]*2\n",
        "b_size = [100]*2\n",
        "l = [1.23, 0.67]\n",
        "a = [53.1, 78.4]\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "df = pd.DataFrame({'Types of Transfer Learning': t, 'Num Epochs': n, 'Learning Rate': lr, 'Drop Out': d_out, 'Hidden Size': h_size, 'Optimizer': optim, 'Weight Decay': w_decay, 'Batch Size': b_size, 'Loss': l, 'Accuracy': a})\n",
        "print(tabulate(df, headers='keys', tablefmt='psql'))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+------------------------------+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n",
            "|    | Types of Transfer Learning   |   Num Epochs |   Learning Rate |   Drop Out |   Hidden Size | Optimizer   |   Weight Decay |   Batch Size |   Loss |   Accuracy |\n",
            "|----+------------------------------+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------|\n",
            "|  0 | Freezing                     |           20 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          100 |   1.23 |       62.1 |\n",
            "|  1 | Fine Tuning                  |           20 |           5e-05 |        0.5 |           500 | Adamax      |         0.0001 |          100 |   0.67 |       83.4 |\n",
            "+----+------------------------------+--------------+-----------------+------------+---------------+-------------+----------------+--------------+--------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD7mDfMqhKA6"
      },
      "source": [
        "Remarks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHZg1GJahMnz"
      },
      "source": [
        "Overall, this assignment was very enjoyable. In comparison to the part (b), the models in (c) took much longer, and for took much longer. In order to yield better results, I would use cross-validation to select the optimal hyperparameters. The most frustrating part of this assignment was knowing that if something looked off, that I would need to train all over again, I guess in a way, this is a good indication of telling me how gruesome it is to train neural networks with a large amount of data. Getting to the end result where we train is rewarding, but if you're impatient, waiting for the neural network to finish training, may be annoying. Overall, I learned a lot, and thoroughly enjoyed the assignment!"
      ]
    }
  ]
}